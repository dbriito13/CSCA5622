{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9824880,"sourceType":"datasetVersion","datasetId":6024843},{"sourceId":9867252,"sourceType":"datasetVersion","datasetId":2401195},{"sourceId":9876776,"sourceType":"datasetVersion","datasetId":2490157}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":20755.809834,"end_time":"2024-12-02T19:05:01.903624","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-02T13:19:06.093790","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Nifty 50 Partial Replication","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.007739,"end_time":"2024-12-02T13:19:08.745185","exception":false,"start_time":"2024-12-02T13:19:08.737446","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Lasso, ElasticNet\nfrom sklearn.metrics import mean_squared_error, r2_score, make_scorer\nfrom sklearn.model_selection import cross_val_score, TimeSeriesSplit, ParameterGrid\nfrom sklearn.linear_model import LassoCV\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nfrom tqdm import tqdm\nimport warnings\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.filterwarnings(\"ignore\")\nwarnings.filterwarnings(\"always\", category=ConvergenceWarning)\nimport seaborn as sns\nfrom sklearn.pipeline import Pipeline\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nimport xgboost as xgb\nfrom sklearn.feature_selection import SelectFromModel,mutual_info_regression","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:15:47.558700Z","iopub.execute_input":"2024-12-05T16:15:47.559248Z","iopub.status.idle":"2024-12-05T16:15:49.826356Z","shell.execute_reply.started":"2024-12-05T16:15:47.559178Z","shell.execute_reply":"2024-12-05T16:15:49.824753Z"},"papermill":{"duration":3.174104,"end_time":"2024-12-02T13:19:11.926534","exception":false,"start_time":"2024-12-02T13:19:08.752430","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def tracking_error(y_true, y_pred):\n\n    # Convert y_true and y_pred to pandas Series for easy handling of pct_change()\n    y_true = pd.Series(y_true)\n    y_pred = pd.Series(y_pred)\n\n    # Calculate percentage change for true values and predictions\n    # pct_change_true = y_true.pct_change() * 100\n    # pct_change_pred = y_pred.pct_change() * 100\n\n    # Calculate the difference between the percentage changes\n    diff_pct_change = y_true - y_pred    \n\n    # Return the standard deviation of the differences (tracking error)\n    return np.std(diff_pct_change.dropna())  # dropna() to avoid NaN values in pct_change","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:15:49.829130Z","iopub.execute_input":"2024-12-05T16:15:49.829725Z","iopub.status.idle":"2024-12-05T16:15:49.836508Z","shell.execute_reply.started":"2024-12-05T16:15:49.829688Z","shell.execute_reply":"2024-12-05T16:15:49.834973Z"},"papermill":{"duration":0.015566,"end_time":"2024-12-02T13:19:11.949194","exception":false,"start_time":"2024-12-02T13:19:11.933628","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def adj_tracking_error(y_true, X_test, model):\n    cost = 0.001  # 0.1% cost\n    X_test_adjusted = X_test.copy()\n    X_test_adjusted[0, :] -= cost  # Subtract cost from the first return of each stock\n\n    # Predict with adjustment\n    y_pred_adjusted = model.predict(X_test_adjusted)\n    return tracking_error(y_true, y_pred_adjusted)","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:15:49.838413Z","iopub.execute_input":"2024-12-05T16:15:49.838950Z","iopub.status.idle":"2024-12-05T16:15:49.851081Z","shell.execute_reply.started":"2024-12-05T16:15:49.838876Z","shell.execute_reply":"2024-12-05T16:15:49.849847Z"},"papermill":{"duration":0.014912,"end_time":"2024-12-02T13:19:11.970710","exception":false,"start_time":"2024-12-02T13:19:11.955798","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Data","metadata":{"papermill":{"duration":0.005994,"end_time":"2024-12-02T13:19:11.984132","exception":false,"start_time":"2024-12-02T13:19:11.978138","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# directory_path = '/kaggle/input/stock-market-data-nifty-50-stocks-1-min-data'\n# pattern = os.path.join(directory_path, \"*.csv\")  # Change \"*.csv\" to match other patterns if needed\n# Get the list of files that match the pattern\n# file_list = glob.glob(pattern)","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:15:49.853836Z","iopub.execute_input":"2024-12-05T16:15:49.854193Z","iopub.status.idle":"2024-12-05T16:15:49.865754Z","shell.execute_reply.started":"2024-12-05T16:15:49.854161Z","shell.execute_reply":"2024-12-05T16:15:49.864426Z"},"papermill":{"duration":0.01444,"end_time":"2024-12-02T13:19:12.004881","exception":false,"start_time":"2024-12-02T13:19:11.990441","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def fetch_data(cols):\n    df_list = []\n    for file in tqdm(file_list):\n        stock_name = os.path.basename(file).split(\"_\")[0]\n        file_df = pd.read_csv(file, index_col=0)\n        file_df = file_df[[cols]]\n        file_df.columns = pd.MultiIndex.from_product([[stock_name], file_df.columns])\n        df_list.append(file_df)\n    return pd.concat(df_list, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:15:49.867509Z","iopub.execute_input":"2024-12-05T16:15:49.867865Z","iopub.status.idle":"2024-12-05T16:15:49.888675Z","shell.execute_reply.started":"2024-12-05T16:15:49.867832Z","shell.execute_reply":"2024-12-05T16:15:49.886779Z"},"papermill":{"duration":0.015652,"end_time":"2024-12-02T13:19:12.026995","exception":false,"start_time":"2024-12-02T13:19:12.011343","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# df = fetch_data('close')\n\n# df.to_csv('/kaggle/inputifty_50_closing.csv')","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:15:49.891255Z","iopub.execute_input":"2024-12-05T16:15:49.891781Z","iopub.status.idle":"2024-12-05T16:15:49.902402Z","shell.execute_reply.started":"2024-12-05T16:15:49.891728Z","shell.execute_reply":"2024-12-05T16:15:49.901270Z"},"papermill":{"duration":0.014432,"end_time":"2024-12-02T13:19:12.047739","exception":false,"start_time":"2024-12-02T13:19:12.033307","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nifty-50-closing-data/nifty_50_closing.csv', index_col=0, header=[0, 1])\ndf = df.xs('close', level=1, axis=1)\ndf.index = pd.to_datetime(df.index)\nnan_rows = df.isna().any(axis=1)\n\n# Get the number of rows with NaN value\nnum_nan_rows = nan_rows.sum()\n\n\nprint(f\"Number of rows with NaN values: {num_nan_rows}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:15:49.903977Z","iopub.execute_input":"2024-12-05T16:15:49.904452Z","iopub.status.idle":"2024-12-05T16:16:10.921608Z","shell.execute_reply.started":"2024-12-05T16:15:49.904393Z","shell.execute_reply":"2024-12-05T16:16:10.919956Z"},"papermill":{"duration":20.950899,"end_time":"2024-12-02T13:19:33.005118","exception":false,"start_time":"2024-12-02T13:19:12.054219","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Number of rows with NaN values: 639555\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"nifty_100_closing = pd.read_csv('/kaggle/input/nifty-50-minute-data/NIFTY 100_minute.csv', index_col=0)[['close']]\nnifty_100_closing.index = pd.to_datetime(nifty_100_closing.index)\nnifty_100_closing.rename(columns={'close': 'NIFTY_100'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:16:10.923490Z","iopub.execute_input":"2024-12-05T16:16:10.924014Z","iopub.status.idle":"2024-12-05T16:16:13.334689Z","shell.execute_reply.started":"2024-12-05T16:16:10.923965Z","shell.execute_reply":"2024-12-05T16:16:13.333490Z"},"papermill":{"duration":2.124504,"end_time":"2024-12-02T13:19:35.135900","exception":false,"start_time":"2024-12-02T13:19:33.011396","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"threshold = 0.10\n\n# Drop columns with more than the threshold percentage of missing values\ndf = df.dropna(thresh=int((1-threshold) * len(df)), axis=1)\n\nnan_rows = df.isna().any(axis=1)\n# Get the number of rows with NaN values\nnum_nan_rows = nan_rows.sum()\nprint(f\"Number of rows with NaN values: {num_nan_rows}\")\ndf.dropna(axis=0, inplace=True)\ndf.index = df.index.tz_localize(None)\nzero_rows = (df == 0.0).any(axis=1)\nnum_zero_rows = zero_rows.sum()\n\nprint(f\"Number of rows with 0.0 values: {num_zero_rows}\")\n\nprint(f\"Total rows {len(df)}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:16:13.336367Z","iopub.execute_input":"2024-12-05T16:16:13.336757Z","iopub.status.idle":"2024-12-05T16:16:14.319663Z","shell.execute_reply.started":"2024-12-05T16:16:13.336721Z","shell.execute_reply":"2024-12-05T16:16:14.318312Z"},"papermill":{"duration":0.644122,"end_time":"2024-12-02T13:19:35.807873","exception":false,"start_time":"2024-12-02T13:19:35.163751","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Number of rows with NaN values: 37207\nNumber of rows with 0.0 values: 79\nTotal rows 639981\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"df_total = df.join(nifty_100_closing, how='left')","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:16:14.323019Z","iopub.execute_input":"2024-12-05T16:16:14.323421Z","iopub.status.idle":"2024-12-05T16:16:14.658939Z","shell.execute_reply.started":"2024-12-05T16:16:14.323386Z","shell.execute_reply":"2024-12-05T16:16:14.657707Z"},"papermill":{"duration":0.32365,"end_time":"2024-12-02T13:19:36.161854","exception":false,"start_time":"2024-12-02T13:19:35.838204","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df_total.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:16:14.660647Z","iopub.execute_input":"2024-12-05T16:16:14.661193Z","iopub.status.idle":"2024-12-05T16:16:14.959400Z","shell.execute_reply.started":"2024-12-05T16:16:14.661133Z","shell.execute_reply":"2024-12-05T16:16:14.958401Z"},"papermill":{"duration":0.29123,"end_time":"2024-12-02T13:19:36.459880","exception":false,"start_time":"2024-12-02T13:19:36.168650","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Calculate the percentage change\nX_pct_change = df_total.pct_change()\n\n# Define the threshold for large changes (e.g., 100% change)\nthreshold = 1.0  # 1.0 corresponds to 100% when working with pct_change()\n\n# Find rows with any column having a percentage change greater than the threshold\nlarge_change_rows = X_pct_change[(X_pct_change.abs() > threshold).any(axis=1)]\n\n# Get the number of rows where there are large percentage changes\nnum_large_changes = large_change_rows.shape[0]\n\nprint(f\"Number of rows with large changes (>{threshold * 100}%): {num_large_changes}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:16:14.960705Z","iopub.execute_input":"2024-12-05T16:16:14.961081Z","iopub.status.idle":"2024-12-05T16:16:17.429379Z","shell.execute_reply.started":"2024-12-05T16:16:14.961037Z","shell.execute_reply":"2024-12-05T16:16:17.428015Z"},"papermill":{"duration":1.91081,"end_time":"2024-12-02T13:19:38.377587","exception":false,"start_time":"2024-12-02T13:19:36.466777","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Number of rows with large changes (>100.0%): 42\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print(len(df_total))","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:16:17.430989Z","iopub.execute_input":"2024-12-05T16:16:17.431365Z","iopub.status.idle":"2024-12-05T16:16:17.438484Z","shell.execute_reply.started":"2024-12-05T16:16:17.431331Z","shell.execute_reply":"2024-12-05T16:16:17.436853Z"},"papermill":{"duration":0.015787,"end_time":"2024-12-02T13:19:38.400422","exception":false,"start_time":"2024-12-02T13:19:38.384635","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"629791\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"df_total.sort_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:16:17.440075Z","iopub.execute_input":"2024-12-05T16:16:17.440443Z","iopub.status.idle":"2024-12-05T16:16:17.691994Z","shell.execute_reply.started":"2024-12-05T16:16:17.440400Z","shell.execute_reply":"2024-12-05T16:16:17.690696Z"},"papermill":{"duration":0.221444,"end_time":"2024-12-02T13:19:38.628543","exception":false,"start_time":"2024-12-02T13:19:38.407099","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":2.370074,"end_time":"2024-12-02T13:19:41.005852","exception":false,"start_time":"2024-12-02T13:19:38.635778","status":"completed"},"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Models","metadata":{"papermill":{"duration":0.006446,"end_time":"2024-12-02T13:19:41.019240","exception":false,"start_time":"2024-12-02T13:19:41.012794","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Combined Approach\n\nIn this section, we will utilize a combined approach to limit the number of features (stocks) and train our models.\n\n\n\n1. Feature Selection (using Lasso w/ high alpha, Mutual Info, ANOVA, RFE)\n\n2. Define threshold to drop features\n\n3. Train model on reduced feature space (Hyperparameter tuned)\n\n4. Get tracking error\n\n5. Save pair (number of stocks, tracking error) for plotting","metadata":{"papermill":{"duration":0.006523,"end_time":"2024-12-02T13:19:41.032427","exception":false,"start_time":"2024-12-02T13:19:41.025904","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Lasso - Lasso\n\n\n\nWe will utilize a Lasso model with a high alpha value to perform feature selection, this will drop the coefficients for less important features to 0. After that we retrain a Lasso model with hyperparameter tuning.","metadata":{"papermill":{"duration":0.006463,"end_time":"2024-12-02T13:19:41.045638","exception":false,"start_time":"2024-12-02T13:19:41.039175","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n\n\ndef Lasso_Lasso(alpha, X, y):    \n    tscv = TimeSeriesSplit(n_splits=18, max_train_size=85000, test_size=30000)\n    stocks = []\n    num_stocks = []\n    fold_scores = []\n    adj_fold_scores = []\n\n    for train_index, test_index in tscv.split(X):\n        X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]\n        y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]\n        train_period = X.iloc[train_index].index\n        test_period = X.iloc[test_index].index\n\n        # Convert to date format\n        train_start_date, train_end_date = train_period.min(), train_period.max()\n        test_start_date, test_end_date = test_period.min(), test_period.max()\n\n        print(f\"Train period: {train_start_date} to {train_end_date}\")\n        print(f\"Test period: {test_start_date} to {test_end_date}\")\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X_train_cv)\n\n        # Feature selection with alpha from list\n        lasso_fs = Lasso(alpha=alpha, max_iter=200)\n        lasso_fs.fit(X_scaled, y_train_cv)\n\n        #for feature, coef in zip(X_train_cv.columns, lasso_fs.coef_)\n        #    print(f\"{feature}: {coef}\")\n\n        selector = SelectFromModel(lasso_fs, threshold=10e-10, max_features=None)  # Adjust threshold as needed\n        X_selected_train = selector.transform(X_scaled)\n        X_selected_test = selector.transform(X_test_cv)\n\n        selected_features = np.where(selector.get_support())[0] \n        print(f\"Selected {len(selected_features)} stocks\")\n        num_stocks.append(len(selected_features))\n        stocks.append(selected_features)\n\n        best_alpha = None\n        best_score = float('inf')  # Assuming lower is better for your metric\n        for alph in [0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.002, 0.0025]:\n            lasso = Lasso(alpha=alph, max_iter=15000)\n            lasso.fit(X_selected_train, y_train_cv)\n            y_pred = lasso.predict(X_selected_test)\n            fold_score = tracking_error(y_test_cv.values, y_pred)\n            adj_fold_score = adj_tracking_error(y_test_cv.values, X_selected_test, lasso)\n            # print(f\"Alpha: {alpha}, Fold Score: {fold_score}\"\n            \n            if fold_score < best_score:\n                best_score = fold_score\n                best_alpha = alpha\n\n        print(f\"Best Alpha for this fold: {best_alpha}, Best Fold Score: {best_score}\")\n        fold_scores.append(best_score)\n        adj_fold_scores.append(adj_fold_score)\n\n    # Calculate the average score across all folds\n    average_score = np.mean(fold_scores)\n    average_adj_score = np.mean(adj_fold_scores)\n\n    # Get average stocks chosen over all folds\n    average_selected_features = np.mean(num_stocks)\n\n    # Print the tracking error for this alpha\n    print(f\"Alpha: {alpha}, Average Tracking Error: {average_score}\")\n    return stocks, average_selected_features, average_score, average_adj_score","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-05T16:16:17.693326Z","iopub.execute_input":"2024-12-05T16:16:17.693657Z","iopub.status.idle":"2024-12-05T16:16:17.707345Z","shell.execute_reply.started":"2024-12-05T16:16:17.693625Z","shell.execute_reply":"2024-12-05T16:16:17.705886Z"},"papermill":{"duration":0.022764,"end_time":"2024-12-02T13:19:41.075078","exception":false,"start_time":"2024-12-02T13:19:41.052314","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def Lasso_Lasso_plot(X,y):\n    alphas = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009]\n    tracking_errors = []\n    adj_tracking_errors = []\n    num_stocks_list = []\n    \n    for alpha in alphas:\n        print(f\"----------Starting alpha {alpha}-------------\")\n        _, num_stocks, tracking_err, adj_tracking_err = Lasso_Lasso(alpha, X, y)\n        num_stocks_list.append(num_stocks)\n        tracking_errors.append(tracking_err)\n        adj_tracking_errors.append(adj_tracking_err)\n    \n    # Plotting the results\n    fig, ax1 = plt.subplots()\n    \n    # Plotting number of stocks on the primary y-axis\n    color = 'tab:blue'    \n    ax1.set_xlabel('Alpha')\n    ax1.set_ylabel('Number of Stocks', color=color)    \n    ax1.plot(alphas, num_stocks_list, color=color, marker='o', label='Number of Stocks')\n    ax1.tick_params(axis='y', labelcolor=color)\n    \n    # Creating a second y-axis for tracking error\n    ax2 = ax1.twinx()\n    color = 'tab:red'\n    ax2.set_ylabel('Tracking Error', color=color)\n    #ax2.plot(alphas, tracking_errors, color='tab:green', marker='o', linestyle='--', label='Tracking Error')\n    ax2.plot(alphas, adj_tracking_errors, color=color, marker='x', linestyle='--', label='Adjusted Tracking Error')\n    ax2.tick_params(axis='y', labelcolor=color)\n    \n    # Adding a title and legend\n    plt.title('Number of Stocks and Tracking Error vs. Alpha')    \n    fig.tight_layout()  # Adjust layout to prevent overlap\n    plt.save_fig('Lasso-Lasso.png')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:16:17.708672Z","iopub.execute_input":"2024-12-05T16:16:17.709124Z","iopub.status.idle":"2024-12-05T16:16:17.727149Z","shell.execute_reply.started":"2024-12-05T16:16:17.709090Z","shell.execute_reply":"2024-12-05T16:16:17.725558Z"},"papermill":{"duration":747.843259,"end_time":"2024-12-02T13:32:08.925401","exception":false,"start_time":"2024-12-02T13:19:41.082142","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### Mutual Info - Lasso\n\nUsing mutual information between variables, which measures the dependency between them, 0 value being independence. By getting the mutual information between the features (stocks) and the target (NIFTY 100) we can \"discard\" the variables with lower dependencies. After feature selection, we traing a Lasso model with CV.","metadata":{"papermill":{"duration":0.025132,"end_time":"2024-12-02T13:32:09.027191","exception":false,"start_time":"2024-12-02T13:32:09.002059","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n\n\ndef MI_Experiment(percentile, X, y, model_class, params):\n    tscv = TimeSeriesSplit(n_splits=18, max_train_size=85000, test_size=30000)\n    stocks = []\n    num_stocks = []\n    fold_scores = []\n    adj_fold_scores = []\n\n    for train_index, test_index in tscv.split(X):\n        X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]\n        y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X_train_cv)\n\n        # Feature selection with alpha from list\n        mi_scores = mutual_info_regression(X_train_cv, y_train_cv)\n        mi_scores_series = pd.Series(mi_scores, index=X_train_cv.columns)\n\n        threshold_value = mi_scores_series.quantile(percentile)        \n\n        selected_features = mi_scores_series[mi_scores_series > threshold_value].index\n        selected_indices = [X_train_cv.columns.get_loc(feature) for feature in selected_features]\n\n        # Filter the NumPy arrays based on the selected feature indices\n        X_train_selected = X_scaled[:, selected_indices]\n        X_test_selected = X_test_cv.to_numpy()[:, selected_indices]\n\n        print(f\"Selected {len(selected_features)} stocks\")\n        num_stocks.append(len(selected_features))\n        stocks.append(selected_features)\n\n        best_params = None\n        best_score = float('inf')  # Assuming lower is better for your metric\n        best_adj_score = float('inf')\n        for param in ParameterGrid(params):\n            print(f\"Trying combination {param}\")\n            model = model_class(**param)\n            model.fit(X_train_selected, y_train_cv)\n\n            y_pred = model.predict(X_test_selected)\n            fold_score = tracking_error(y_test_cv.values, y_pred)\n            adj_fold_score = adj_tracking_error(y_test_cv.values, X_test_selected, model)\n            # print(f\"Alpha: {alpha}, Fold Score: {fold_score}\")\n\n            if adj_fold_score < best_adj_score:\n                best_score = fold_score\n                best_adj_score = adj_fold_score\n                best_params = param\n\n        print(f\"Best Params for this fold: {best_params}, Best Fold Score: {best_score}\")\n        fold_scores.append(best_score)\n        adj_fold_scores.append(best_adj_score)\n\n    # Calculate the average score across all folds\n    average_score = np.mean(fold_scores)\n    average_adj_score = np.mean(adj_fold_scores)\n\n    # Get average stocks chosen over all folds\n    average_selected_features = np.mean(num_stocks)\n\n    # Print the tracking error for this alpha\n    print(f\"Percentile: {percentile}, Tracking Error: {average_score}, Adj Tracking Error: {average_adj_score}\")\n    return stocks, average_selected_features, average_score, average_adj_score","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:16:17.729319Z","iopub.execute_input":"2024-12-05T16:16:17.730543Z","iopub.status.idle":"2024-12-05T16:16:17.751184Z","shell.execute_reply.started":"2024-12-05T16:16:17.730491Z","shell.execute_reply":"2024-12-05T16:16:17.749773Z"},"papermill":{"duration":0.04052,"end_time":"2024-12-02T13:32:09.093172","exception":false,"start_time":"2024-12-02T13:32:09.052652","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"### MI - Lasso","metadata":{}},{"cell_type":"code","source":"def MI_Lasso_plot(X,y):\n    tracking_errors = []\n    adj_tracking_errors = []\n    num_stocks_list = []\n    \n    percentiles = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n    param_grid = {\n        'alpha': [0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.002, 0.0025],\n        'max_iter': [15000]\n    }\n    \n    for percentile in percentiles:\n        print(f\"Starting percentile: {percentile}\")\n        _, num_stocks, tracking_err, adj_tracking_err = MI_Experiment(percentile, X, y, Lasso, param_grid)\n        num_stocks_list.append(num_stocks)\n        tracking_errors.append(tracking_err)\n        adj_tracking_errors.append(adj_tracking_err)\n    \n    # Plotting the results\n    fig, ax1 = plt.subplots()\n    \n    # Plotting number of stocks on the primary y-axis\n    plt.plot(num_stocks_list, adj_tracking_errors, marker='x')\n    plt.xlabel('Number of Stocks')\n    plt.ylabel('Tracking Error')\n    plt.title('Lasso - Tracking Errors vs Number of Stocks')\n    plt.grid(True)\n    plt.savefig(\"MI-Lasso.png\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:16:17.752738Z","iopub.execute_input":"2024-12-05T16:16:17.753131Z","iopub.status.idle":"2024-12-05T16:16:17.774162Z","shell.execute_reply.started":"2024-12-05T16:16:17.753098Z","shell.execute_reply":"2024-12-05T16:16:17.772672Z"},"papermill":{"duration":7820.791352,"end_time":"2024-12-02T15:42:29.909960","exception":false,"start_time":"2024-12-02T13:32:09.118608","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"### MI - ElasticNet","metadata":{"papermill":{"duration":0.07641,"end_time":"2024-12-02T15:42:30.064196","exception":false,"start_time":"2024-12-02T15:42:29.987786","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def MI_ElasticNet_plot(X,y):\n    tracking_errors = []\n    adj_tracking_errors = []\n    num_stocks_list = []\n    \n    percentiles = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n    param_grid = {\n        'alpha': [0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.002, 0.0025],\n        'l1_ratio': [0.1, 0.5, 0.7, 0.9]\n    }\n    \n    for percentile in percentiles:\n        print(f\"Starting percentile: {percentile}\")\n        _, num_stocks, tracking_err, adj_tracking_err = MI_Experiment(percentile, X, y, ElasticNet, param_grid)\n        num_stocks_list.append(num_stocks)\n        tracking_errors.append(tracking_err)\n        adj_tracking_errors.append(adj_tracking_err)\n    \n    # Plotting the results\n    fig, ax1 = plt.subplots()\n    \n    # Plotting number of stocks on the primary y-axis\n    plt.plot(num_stocks_list, adj_tracking_errors, marker='x')\n    plt.xlabel('Number of Stocks')\n    plt.ylabel('Tracking Error')\n    plt.title('ElasticNet - Tracking Errors vs Number of Stocks ')\n    plt.grid(True)\n    plt.savefig(\"MI-ElasticNet.png\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:16:17.776144Z","iopub.execute_input":"2024-12-05T16:16:17.776555Z","iopub.status.idle":"2024-12-05T16:16:17.791713Z","shell.execute_reply.started":"2024-12-05T16:16:17.776520Z","shell.execute_reply":"2024-12-05T16:16:17.790365Z"},"papermill":{"duration":9653.410145,"end_time":"2024-12-02T18:23:23.552432","exception":false,"start_time":"2024-12-02T15:42:30.142287","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"TODO: Theil-Sein Linear Regression","metadata":{"execution":{"iopub.execute_input":"2024-11-12T21:50:37.572889Z","iopub.status.busy":"2024-11-12T21:50:37.570440Z"},"papermill":{"duration":0.269963,"end_time":"2024-12-02T18:23:24.098548","exception":false,"start_time":"2024-12-02T18:23:23.828585","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### MI-RandomForestRegressor","metadata":{}},{"cell_type":"code","source":"def MI_RF_plot(X,y):\n    tracking_errors = []\n    adj_tracking_errors = []\n    num_stocks_list = []\n    \n    percentiles = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n    param_grid = {\n        'n_estimators': [10, 20, 30, 40, 50],       # Number of trees in the forest\n        'max_depth': [5, 10, 15],      # Maximum depth of the tree\n        'max_samples': [0.5],\n        'min_samples_split': [0.05],\n        'bootstrap': [True],\n        'n_jobs': [-1],\n        'max_features': ['sqrt']\n    }\n    \n    for percentile in percentiles:\n        print(f\"Starting percentile: {percentile}\")\n        _, num_stocks, tracking_err, adj_tracking_err = MI_Experiment(percentile, X, y, RandomForestRegressor, param_grid)\n        num_stocks_list.append(num_stocks)\n        tracking_errors.append(tracking_err)\n        adj_tracking_errors.append(adj_tracking_err)\n    \n    # Plotting the results\n    fig, ax1 = plt.subplots()\n    \n    # Plotting number of stocks on the primary y-axis\n    plt.plot(num_stocks_list, adj_tracking_errors, marker='x')\n    plt.xlabel('Number of Stocks')\n    plt.ylabel('Tracking Error')\n    plt.title('RandomForestRegressor - Tracking Errors vs Number of Stocks ')\n    plt.grid(True)\n    plt.savefig(\"MI-RandomForestRegressor.png\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-05T16:16:17.793421Z","iopub.execute_input":"2024-12-05T16:16:17.793833Z","iopub.status.idle":"2024-12-05T16:16:17.818689Z","shell.execute_reply.started":"2024-12-05T16:16:17.793799Z","shell.execute_reply":"2024-12-05T16:16:17.817168Z"},"papermill":{"duration":2495.391087,"end_time":"2024-12-02T19:04:59.756301","exception":false,"start_time":"2024-12-02T18:23:24.365214","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"### MI - XGBoost","metadata":{}},{"cell_type":"code","source":"def MI_XGBoost_plot(X,y):\n    tracking_errors = []\n    adj_tracking_errors = []\n    num_stocks_list = []\n    \n    percentiles = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n    param_grid = {\n        'n_estimators': [50, 100, 200],  # Number of boosting rounds\n        'learning_rate': [0.01, 0.1],  # Step size shrinkage\n        'max_depth': [3, 5, 7],  # Maximum depth of a tree\n        'n_jobs': [-1],\n        'tree_method': ['gpu_hist'],\n    }\n    \n    for percentile in percentiles:\n        print(f\"Starting percentile: {percentile}\")\n        _, num_stocks, tracking_err, adj_tracking_err = MI_Experiment(percentile, X, y, xgb.XGBRegressor, param_grid)\n        num_stocks_list.append(num_stocks)\n        tracking_errors.append(tracking_err)\n        adj_tracking_errors.append(adj_tracking_err)\n    \n    # Plotting the results\n    fig, ax1 = plt.subplots()\n    \n    # Plotting number of stocks on the primary y-axis\n    plt.plot(num_stocks_list, adj_tracking_errors, marker='x')\n    plt.xlabel('Number of Stocks')\n    plt.ylabel('Tracking Error')\n    plt.title('XGBRegressor - Tracking Errors vs Number of Stocks ')\n    plt.grid(True)\n    plt.savefig(\"MI-RandomForestRegressor.png\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:16:17.820633Z","iopub.execute_input":"2024-12-05T16:16:17.821108Z","iopub.status.idle":"2024-12-05T16:16:17.841957Z","shell.execute_reply.started":"2024-12-05T16:16:17.821073Z","shell.execute_reply":"2024-12-05T16:16:17.840328Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"df_total_z = df_total.replace(0, np.nan)  # Convert zeroes back to NaNs\ndf_total_returns = df_total_z.pct_change().dropna()\ndf_total_returns = 100*df_total_returns\nX = df_total_returns.drop(columns=['NIFTY 50', 'NIFTY BANK', 'NIFTY_100'])\ny = df_total_returns['NIFTY_100']","metadata":{"papermill":{"duration":0.284962,"end_time":"2024-12-02T19:05:00.328044","exception":false,"start_time":"2024-12-02T19:05:00.043082","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:16:17.844002Z","iopub.execute_input":"2024-12-05T16:16:17.844417Z","iopub.status.idle":"2024-12-05T16:16:21.202590Z","shell.execute_reply.started":"2024-12-05T16:16:17.844366Z","shell.execute_reply":"2024-12-05T16:16:21.201440Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"MI_XGBoost_plot(X,y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:16:21.204069Z","iopub.execute_input":"2024-12-05T16:16:21.204520Z"}},"outputs":[{"name":"stdout","text":"Starting percentile: 0.2\nSelected 68 stocks\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nBest Params for this fold: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}, Best Fold Score: 0.037229880526734545\nSelected 68 stocks\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nBest Params for this fold: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}, Best Fold Score: 0.04284679640074626\nSelected 68 stocks\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nBest Params for this fold: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}, Best Fold Score: 0.02807089847141063\nSelected 68 stocks\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nBest Params for this fold: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}, Best Fold Score: 0.027143296213207255\nSelected 68 stocks\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nBest Params for this fold: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}, Best Fold Score: 0.03050900306109359\nSelected 68 stocks\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nBest Params for this fold: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}, Best Fold Score: 0.03960223704288793\nSelected 68 stocks\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nBest Params for this fold: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}, Best Fold Score: 0.03199757872976967\nSelected 68 stocks\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nBest Params for this fold: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}, Best Fold Score: 0.04883109124946027\nSelected 68 stocks\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nBest Params for this fold: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}, Best Fold Score: 0.038536549496974666\nSelected 68 stocks\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\nBest Params for this fold: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}, Best Fold Score: 0.04427720656625039\nSelected 68 stocks\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}\nTrying combination {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'n_jobs': -1}\n","output_type":"stream"}],"execution_count":null}]}